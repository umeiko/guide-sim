{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e49d1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from vit_pytorch import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4c1136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(weights=None) \n",
    "resnet18.conv1  = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "resnet18.avgpool  = nn.AdaptiveAvgPool2d(output_size=(2, 2))\n",
    "resnet18.fc  = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dbb8e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c7ea9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(1, 1, 256, 256)\n",
    "resnet18(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebe792ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=32, p2=32)\n",
       "    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (transformer): Transformer(\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x ModuleList(\n",
       "        (0): Attention(\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attend): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "            (5): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit = ViT(\n",
    "        image_size = 256,\n",
    "        channels = 1,\n",
    "        patch_size = 32,\n",
    "        num_classes = 5,\n",
    "        dim = 1024,\n",
    "        depth = 3,\n",
    "        heads = 16,\n",
    "        mlp_dim = 2048,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "    )\n",
    "vit.mlp_head = nn.Identity()\n",
    "vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a71b519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(1, 1, 256, 256)\n",
    "vit(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60102d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_bn_with_identity(module:nn.Module):\n",
    "    # 遍历当前模块的所有子模块\n",
    "    for name, child in module.named_children(): \n",
    "        # 如果是 BN 层，则替换为 Identity \n",
    "        if isinstance(child, nn.BatchNorm2d):\n",
    "            setattr(module, name, nn.Identity())\n",
    "        else:\n",
    "            # 对非 BN 子模块递归调用\n",
    "            replace_bn_with_identity(child)\n",
    "\n",
    "def initialize_weights(module:nn.modules):\n",
    "    # 遍历当前模块的所有子模块\n",
    "        for name, child in module.named_children(): \n",
    "            # 如果是 BN 层，则替换为 Identity \n",
    "            if isinstance(child, nn.Conv2d) or isinstance(child, nn.Linear):\n",
    "                # nn.init.orthogonal_(module.weight, nn.init.calculate_gain('relu'))\n",
    "                nn.init.xavier_uniform_(child.weight)\n",
    "                # nn.init.kaiming_uniform_(module.weight)\n",
    "                if child.bias is not None:\n",
    "                    nn.init.constant_(child.bias, 0)\n",
    "            else:\n",
    "                replace_bn_with_identity(child)\n",
    "class Hybrid_RESNET18_VIT3_FC(nn.Module):\n",
    "    def __init__(self, input_channels=1, act_num=5, use_softmax=True):\n",
    "        super().__init__()\n",
    "        self.input_shape = (input_channels, 256, 256)\n",
    "        # resnet18构造\n",
    "        self.resnet18 = models.resnet18(weights=None) \n",
    "        replace_bn_with_identity(self.resnet18)\n",
    "        self.resnet18.conv1  = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet18.fc  = nn.Identity()  # 使用 Identity 替代 fc 层\n",
    "        self.use_softmax = use_softmax\n",
    "        # VIT 构造\n",
    "        self.vit = ViT(\n",
    "                image_size = 256,\n",
    "                channels = input_channels,\n",
    "                patch_size = 32,\n",
    "                num_classes = 5,\n",
    "                dim = 1024,\n",
    "                depth = 3,\n",
    "                heads = 16,\n",
    "                mlp_dim = 2048,\n",
    "                dropout = 0.1,\n",
    "                emb_dropout = 0.1\n",
    "            )\n",
    "        self.vit.mlp_head = nn.Linear(1024, 512)\n",
    "        self.use_softmax = use_softmax\n",
    "        \n",
    "        self.hybrid_linear = nn.Linear(1024, 1024)\n",
    "        \n",
    "        self.critic_linear = nn.Linear(1024, 1)\n",
    "        self.actor_linear = nn.Linear(1024, act_num)\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        for k, shape in enumerate(self.input_shape):\n",
    "            if x.shape[k+1] != shape:\n",
    "                raise ValueError(f\"Input shape should be {self.input_shape}, got {x.shape[1:]}\")\n",
    "        # [b, 512]\n",
    "        x1 = self.resnet18(x)\n",
    "        # [b, 512]\n",
    "        x2 = self.vit(x)\n",
    "        # [b, 1024]\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = F.relu(self.hybrid_linear(x))\n",
    "        \n",
    "        if self.use_softmax:\n",
    "            a = F.softmax(self.actor_linear(x), dim=1)\n",
    "        else:\n",
    "            a = self.actor_linear(x)\n",
    "        return a, self.critic_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d74e86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = Hybrid_RESNET18_VIT3_FC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "532ebbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(1, 1, 256, 256)\n",
    "act, v = hy(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "909ded47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act.shape\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385034d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
